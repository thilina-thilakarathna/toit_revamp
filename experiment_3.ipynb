{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ec7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ATTRS = ['speed', 'latency', 'bandwidth', 'coverage', 'reliability', 'security']\n",
    "D_COLS = [f\"D_{a}\" for a in ATTRS]\n",
    "\n",
    "\n",
    "class Sophistication:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect_sophistication(self, correct_data, tampered_data, weight):\n",
    "        results_review = {}\n",
    "\n",
    "        df_sct = tampered_data.copy()\n",
    "        # df_sct['label'] = df_sct['true_label']   # use ground truth for sanity-check\n",
    "        df_sct = df_sct[df_sct['label'] == 'T'].copy()\n",
    "\n",
    "    \n",
    "        # df_sct = self._ensure_D_cols(df_sct)\n",
    "\n",
    "        # your helper (must exist in your notebook)\n",
    "        # tampered_dict = dataframe_devide_to_microcell_dictionary(df_sct)\n",
    "        df2 = df_sct\n",
    "      \n",
    "        # df2 = self._ensure_D_cols(df2)รท\n",
    "\n",
    "        # df2_received = df2[(df2['label'] == 'T') & (df2['origin'] == 'R')].copy()\n",
    "        df2_generated = df2[(df2['label'] == 'T') & (df2['origin'] == 'G')].copy()\n",
    "\n",
    "        # if not df2_received.empty:\n",
    "        #     df2_received = self._process_received_data(df2_received, correct_data)\n",
    "\n",
    "        if not df2_generated.empty:\n",
    "            df2_generated = self._process_generated_data(df2_generated, correct_data)\n",
    "\n",
    "        \n",
    "\n",
    "        # combined_microcell_df = pd.concat([df2_generated, df2_received], ignore_index=True)\n",
    "        combined_microcell_df = df2_generated\n",
    "        print(combined_microcell_df)\n",
    "\n",
    "        \n",
    "\n",
    "            \n",
    "        #     combined_microcell_df = self._ensure_D_cols(combined_microcell_df)\n",
    "\n",
    "        #     # filter out NC comparisons\n",
    "        combined_microcell_df = combined_microcell_df[combined_microcell_df['D_speed'] != 'NC'].copy()\n",
    "\n",
    "        #     # optional: filter zeros\n",
    "        combined_microcell_df = combined_microcell_df[\n",
    "                (combined_microcell_df['speed'] != 0) &\n",
    "                (combined_microcell_df['latency'] != 0) &\n",
    "                (combined_microcell_df['bandwidth'] != 0) &\n",
    "                (combined_microcell_df['coverage'] != 0) &\n",
    "                (combined_microcell_df['reliability'] != 0) &\n",
    "                (combined_microcell_df['security'] != 0)\n",
    "            ].copy()\n",
    "\n",
    "        combined_microcell_df = combined_microcell_df.reset_index(drop=True)\n",
    "\n",
    "        nc_count = combined_microcell_df['D_speed'].value_counts().get('NC', 0)\n",
    "        total_count = len(combined_microcell_df)\n",
    "\n",
    "  \n",
    "            # print(\"Count of 'NC':\", nc_count)\n",
    "            # print(\"Total count:\", total_count)\n",
    "\n",
    "  \n",
    "        df = combined_microcell_df.copy().reset_index(drop=True)\n",
    "\n",
    "        impact = self._calculate_impact(df, weight)\n",
    "        sig = self._calculate_significance(df, weight)\n",
    "        trend = self._calculate_trend(df, correct_data)\n",
    "\n",
    "        new_df = pd.DataFrame({'Impact': impact, 'Significance': sig, 'Trend': trend})\n",
    "        # print(new_df)\n",
    "        mean_impact = new_df['Impact'].mean()\n",
    "        mean_sig    = new_df['Significance'].mean()\n",
    "        mean_trend  = new_df['Trend'].mean()\n",
    "        label = self.classify_sophistication(mean_impact, mean_sig, mean_trend)\n",
    "\n",
    "        # print(\"Impact:\", mean_impact)\n",
    "        # print(\"Significance:\", mean_sig)\n",
    "        # print(\"Trend:\", mean_trend)\n",
    "        # print(\"Detected Sophistication:\", label)\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "        return label\n",
    "    \n",
    "\n",
    "    def classify_sophistication(self, mean_impact, mean_sig, mean_trend,\n",
    "                                t_trend_high=0.95,\n",
    "                                t_trend_low=0.2,\n",
    "                                t_sig=0.05,\n",
    "                                t_impact=0.05):\n",
    "\n",
    "        # Naive\n",
    "        if mean_trend < t_trend_low and mean_sig < t_sig:\n",
    "            return \"N\"\n",
    "\n",
    "        # Sophisticated\n",
    "        if mean_trend >= t_trend_high and mean_impact <= t_impact:\n",
    "            return \"S\"\n",
    "\n",
    "        # Knowledgeable\n",
    "        return \"K\"\n",
    "\n",
    "\n",
    "    def _process_received_data(self, df_received, correct_data):\n",
    "        # df_received = self._ensure_D_cols(df_received)\n",
    "\n",
    "        for i, row in df_received.iterrows():\n",
    "            origin_record = correct_data[correct_data['serviceid'] == row['serviceid']]\n",
    "            if origin_record.empty:\n",
    "                df_received.loc[i, D_COLS] = ['NC'] * 6\n",
    "            else:\n",
    "                df_received.loc[i, D_COLS] = origin_record[ATTRS].iloc[0].values\n",
    "\n",
    "        return df_received\n",
    "\n",
    "    def _process_generated_data(self, df_generated, correct_data):\n",
    "        # df_generated = self._ensure_D_cols(df_generated)\n",
    "\n",
    "        for i, row in df_generated.iterrows():\n",
    "            provider_other_df = correct_data[\n",
    "                (correct_data['providerid'] == row['providerid'])\n",
    "            ]\n",
    "\n",
    "            if len(provider_other_df) > 1:\n",
    "                mean_values = provider_other_df[ATTRS].mean()\n",
    "                df_generated.loc[i, D_COLS] = mean_values.values\n",
    "            else:\n",
    "                df_generated.loc[i, D_COLS] = ['NC'] * 6\n",
    "\n",
    "        return df_generated\n",
    "\n",
    "    def _calculate_impact(self, df_row, weight):\n",
    "        # ensure numeric for subtraction (in case strings slipped through)\n",
    "        d_speed = df_row['speed'] - df_row['D_speed']\n",
    "        d_latency = df_row['latency'] - df_row['D_latency']\n",
    "        d_bandwidth = df_row['bandwidth'] - df_row['D_bandwidth']\n",
    "        d_coverage = df_row['coverage'] - df_row['D_coverage']\n",
    "        d_reliability = df_row['reliability'] - df_row['D_reliability']\n",
    "        d_security = df_row['security'] - df_row['D_security']\n",
    "\n",
    "        impact = (\n",
    "            d_speed * weight[0] +\n",
    "            d_latency * weight[1] +\n",
    "            d_bandwidth * weight[2] +\n",
    "            d_coverage * weight[3] +\n",
    "            d_reliability * weight[4] +\n",
    "            d_security * weight[5]\n",
    "        ).div(5)\n",
    "\n",
    "        impact = impact.clip(lower=0)\n",
    "        return impact\n",
    "\n",
    "    def _calculate_significance(self, df_row, weight1):\n",
    "        power = 1\n",
    "        powered_matrix = [x ** power for x in weight1]\n",
    "        total_sum = sum(powered_matrix)\n",
    "        weight = [x / total_sum for x in powered_matrix]\n",
    "\n",
    "        sig_list = []\n",
    "        for i in range(len(df_row)):\n",
    "            # if all attributes equal (weird sentinel), significance = 0\n",
    "            if (df_row.iloc[i]['speed'] == df_row.iloc[i]['latency'] == df_row.iloc[i]['bandwidth'] ==\n",
    "                df_row.iloc[i]['coverage'] == df_row.iloc[i]['reliability'] == df_row.iloc[i]['security']):\n",
    "                sig_list.append(0)\n",
    "                continue\n",
    "\n",
    "            d = [\n",
    "                df_row.iloc[i]['speed'] - df_row.iloc[i]['D_speed'],\n",
    "                df_row.iloc[i]['latency'] - df_row.iloc[i]['D_latency'],\n",
    "                df_row.iloc[i]['bandwidth'] - df_row.iloc[i]['D_bandwidth'],\n",
    "                df_row.iloc[i]['coverage'] - df_row.iloc[i]['D_coverage'],\n",
    "                df_row.iloc[i]['reliability'] - df_row.iloc[i]['D_reliability'],\n",
    "                df_row.iloc[i]['security'] - df_row.iloc[i]['D_security']\n",
    "            ]\n",
    "\n",
    "            num_changed = sum(abs(x) > 0 for x in d)\n",
    "            if num_changed == 0:\n",
    "                sig_list.append(0)\n",
    "                continue\n",
    "\n",
    "            # counts only positive-direction changes (your original behavior)\n",
    "            significance = (\n",
    "                (1 if d[0] > 0 else 0) * weight[0] +\n",
    "                (1 if d[1] > 0 else 0) * weight[1] +\n",
    "                (1 if d[2] > 0 else 0) * weight[2] +\n",
    "                (1 if d[3] > 0 else 0) * weight[3] +\n",
    "                (1 if d[4] > 0 else 0) * weight[4] +\n",
    "                (1 if d[5] > 0 else 0) * weight[5]\n",
    "            )\n",
    "\n",
    "            significance = max(significance, 0)\n",
    "            sig_list.append(significance / num_changed)\n",
    "\n",
    "        return sig_list\n",
    "\n",
    "    def _calculate_trend(self, df_row, dfcorrect):\n",
    "        trend_list = []\n",
    "\n",
    "        for i in range(len(df_row)):\n",
    "            if (df_row.iloc[i]['speed'] == df_row.iloc[i]['latency'] == df_row.iloc[i]['bandwidth'] ==\n",
    "                df_row.iloc[i]['coverage'] == df_row.iloc[i]['reliability'] == df_row.iloc[i]['security']):\n",
    "                trend_list.append(0)\n",
    "                continue\n",
    "\n",
    "            temp_df = dfcorrect[dfcorrect['providerid'] == df_row.iloc[i]['providerid']]\n",
    "            temp_df = temp_df[temp_df['serviceid'] != df_row.iloc[i]['serviceid']]\n",
    "\n",
    "            if temp_df.shape[0] > 0:\n",
    "                means = temp_df[ATTRS].mean()\n",
    "\n",
    "                s_trend = df_row.iloc[i]['speed'] - means['speed']\n",
    "                l_trend = df_row.iloc[i]['latency'] - means['latency']\n",
    "                b_trend = df_row.iloc[i]['bandwidth'] - means['bandwidth']\n",
    "                c_trend = df_row.iloc[i]['coverage'] - means['coverage']\n",
    "                r_trend = df_row.iloc[i]['reliability'] - means['reliability']\n",
    "                sec_trend = df_row.iloc[i]['security'] - means['security']\n",
    "\n",
    "                total_trend = (\n",
    "                    self._normalize_trend(s_trend) +\n",
    "                    self._normalize_trend(l_trend) +\n",
    "                    self._normalize_trend(b_trend) +\n",
    "                    self._normalize_trend(c_trend) +\n",
    "                    self._normalize_trend(r_trend) +\n",
    "                    self._normalize_trend(sec_trend)\n",
    "                ) / 6\n",
    "\n",
    "                total_trend = max(total_trend, 0)\n",
    "            else:\n",
    "                total_trend = 'NC'\n",
    "\n",
    "            trend_list.append(total_trend)\n",
    "\n",
    "        return trend_list\n",
    "\n",
    "    def _normalize_trend(self, trend_value):\n",
    "        min_value = 0\n",
    "        max_value = 5\n",
    "        score = 1 - (trend_value - min_value) / (max_value - min_value)\n",
    "        return max(0, min(score, 1))\n",
    "\n",
    "\n",
    "# usage\n",
    "sophistication = Sophistication()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc75461d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing evaluation data from CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluations.evaluation_data.evaluation_data import EvaluationData\n",
    "from tampering.tampering import Tampering\n",
    "from timf.timf import TIMF\n",
    "from data_service.data_service import DataService\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "evaluation_data = EvaluationData()\n",
    "tampering = Tampering()    \n",
    "data_service = DataService()\n",
    "timf = TIMF(data_service)\n",
    "data = evaluation_data.get_data()\n",
    "\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371.0 * c\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def compute_metrics_from_labels(y_true_labels, y_pred_labels):\n",
    "    \"\"\"\n",
    "    Inputs are arrays/Series with values 'T' or 'C'\n",
    "    \"\"\"\n",
    "    y_true = (pd.Series(y_true_labels) == 'T').astype(int)\n",
    "    y_pred = (pd.Series(y_pred_labels) == 'T').astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        auc = None\n",
    "\n",
    "    return accuracy, precision, recall, auc\n",
    "\n",
    "def _to_bin_labels(y):\n",
    "    \"\"\"Map labels to 0/1 where 'T' is positive (1), everything else is 0.\"\"\"\n",
    "    return np.array([1 if str(v) == 'T' else 0 for v in y], dtype=int)\n",
    "\n",
    "def safe_auc(y_true_labels, y_scores):\n",
    "    \"\"\"\n",
    "    Robust AUC:\n",
    "    - returns np.nan if empty or only one class present\n",
    "    - expects y_true_labels like ['T','C',...] and y_scores numeric\n",
    "    \"\"\"\n",
    "    if y_true_labels is None or y_scores is None:\n",
    "        return np.nan\n",
    "    if len(y_true_labels) == 0 or len(y_scores) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    y_true_bin = _to_bin_labels(y_true_labels)\n",
    "    y_scores = np.asarray(y_scores, dtype=float)\n",
    "\n",
    "    # lengths must match\n",
    "    if y_true_bin.shape[0] != y_scores.shape[0]:\n",
    "        raise ValueError(f\"AUC length mismatch: y_true={len(y_true_bin)} vs y_score={len(y_scores)}\")\n",
    "\n",
    "    # AUC needs both classes\n",
    "    if np.unique(y_true_bin).size < 2:\n",
    "        return np.nan\n",
    "\n",
    "    return float(roc_auc_score(y_true_bin, y_scores))\n",
    "\n",
    "def compute_metrics_from_labels(y_true_labels, y_pred_labels):\n",
    "    \"\"\"\n",
    "    Your existing label-based metrics (Accuracy / Precision / Recall).\n",
    "    Assumes positive class is 'T'.\n",
    "    \"\"\"\n",
    "    y_true_bin = _to_bin_labels(y_true_labels)\n",
    "    y_pred_bin = _to_bin_labels(y_pred_labels)\n",
    "\n",
    "    acc = float(accuracy_score(y_true_bin, y_pred_bin))\n",
    "    prec = float(precision_score(y_true_bin, y_pred_bin, zero_division=0))\n",
    "    rec = float(recall_score(y_true_bin, y_pred_bin, zero_division=0))\n",
    "    return acc, prec, rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069f52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: Tampering Type=N, Percentage=10%\n",
      "Empty DataFrame\n",
      "Columns: [serviceid, providerid, gen_microcell, latitude, longitude, timestamp, speed, latency, bandwidth, coverage, reliability, security, origin, true_label, true_label_spa, true_label_bma, currect_microcell, label, score_R, score_G, score]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'D_speed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/paper1/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'D_speed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    109\u001b[39m     microcell_data_all= pd.concat([microcell_data_all, df_tda], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# print(microcell_data_all)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m pred = \u001b[43msophistication\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetect_sophistication\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmicrocell_data_all\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m results_acc.append({\n\u001b[32m    116\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtampering_type\u001b[39m\u001b[33m\"\u001b[39m: tampering_type,\n\u001b[32m    117\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtampering_percentage\u001b[39m\u001b[33m\"\u001b[39m: tampering_percentage,\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcorrect\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(pred == tampering_type),\n\u001b[32m    121\u001b[39m })\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# if out == tampering_type:\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m#     print(\"correct\")\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m \n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m#     # print(tampering_percentage,remote_data['true_label'].value_counts())\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mSophistication.detect_sophistication\u001b[39m\u001b[34m(self, correct_data, tampered_data, weight)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(combined_microcell_df)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m#     combined_microcell_df = self._ensure_D_cols(combined_microcell_df)\u001b[39;00m\n\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m#     # filter out NC comparisons\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m combined_microcell_df = combined_microcell_df[\u001b[43mcombined_microcell_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mD_speed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m != \u001b[33m'\u001b[39m\u001b[33mNC\u001b[39m\u001b[33m'\u001b[39m].copy()\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m#     # optional: filter zeros\u001b[39;00m\n\u001b[32m     52\u001b[39m combined_microcell_df = combined_microcell_df[\n\u001b[32m     53\u001b[39m         (combined_microcell_df[\u001b[33m'\u001b[39m\u001b[33mspeed\u001b[39m\u001b[33m'\u001b[39m] != \u001b[32m0\u001b[39m) &\n\u001b[32m     54\u001b[39m         (combined_microcell_df[\u001b[33m'\u001b[39m\u001b[33mlatency\u001b[39m\u001b[33m'\u001b[39m] != \u001b[32m0\u001b[39m) &\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m         (combined_microcell_df[\u001b[33m'\u001b[39m\u001b[33msecurity\u001b[39m\u001b[33m'\u001b[39m] != \u001b[32m0\u001b[39m)\n\u001b[32m     59\u001b[39m     ].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/paper1/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/paper1/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'D_speed'"
     ]
    }
   ],
   "source": [
    "tampering_percentages = list(range(10, 20, 10))\n",
    "\n",
    "tampering_types = [\"N\", \"K\", \"S\"]  # Naive, Knowledgeable, Sophisticated\n",
    "# tampering_types = [\"S\"]\n",
    "        \n",
    "results_acc = []\n",
    "\n",
    "for tampering_type in tampering_types:\n",
    "    for tampering_percentage in tampering_percentages:\n",
    "\n",
    "        print(f\"Experiment: Tampering Type={tampering_type}, Percentage={tampering_percentage}%\")\n",
    "\n",
    "        for assessing_mic in data['gen_microcell'].unique():\n",
    "            full_df = data.copy()\n",
    "            df_microcell = data[data['gen_microcell'] == assessing_mic].copy()\n",
    "            remaining_df = data[data['gen_microcell'] != assessing_mic].copy()\n",
    "\n",
    "            # -------- Remote tampering (BMA) --------\n",
    "            bma_tampered_df = tampering.bma_tampering(\n",
    "                remaining_df.reset_index(drop=True),\n",
    "                tampering_percentage,\n",
    "                tampering_type\n",
    "            )\n",
    "            remote_data = bma_tampered_df\n",
    "            # remote_data= remaining_df\n",
    "\n",
    "            # remote_data = data[data['gen_microcell'] != assessing_mic].reset_index(drop=True)\n",
    "\n",
    "            # -------- Replication logic --------\n",
    "            microcell_coords = full_df.groupby('gen_microcell')[['latitude', 'longitude']].first().reset_index()\n",
    "            current_coords = microcell_coords[microcell_coords['gen_microcell'] == assessing_mic]\n",
    "\n",
    "            if not current_coords.empty:\n",
    "                lat1 = current_coords['latitude'].values[0]\n",
    "                lon1 = current_coords['longitude'].values[0]\n",
    "\n",
    "                df_microcell_part = df_microcell.copy()\n",
    "                df_microcell_part.loc[:, 'currect_microcell'] = assessing_mic\n",
    "\n",
    "                replicated_parts = [df_microcell_part]\n",
    "\n",
    "                for provider_id in df_microcell['providerid'].unique():\n",
    "\n",
    "                    provider_remote = remote_data[remote_data['providerid'] == provider_id]\n",
    "                    candidate_microcells = []\n",
    "\n",
    "                    for _, row in microcell_coords.iterrows():\n",
    "                        if row['gen_microcell'] == assessing_mic:\n",
    "                            continue\n",
    "                        if (provider_remote['gen_microcell'] == row['gen_microcell']).any():\n",
    "                            dist = _haversine_km(lat1, lon1, row['latitude'], row['longitude'])\n",
    "                            candidate_microcells.append((row['gen_microcell'], dist))\n",
    "\n",
    "                    candidate_microcells.sort(key=lambda x: x[1])\n",
    "                    nearby_microcells = [m for m, _ in candidate_microcells[:38]]\n",
    "\n",
    "                    if nearby_microcells:\n",
    "                        df_remote = remote_data[\n",
    "                            (remote_data['providerid'] == provider_id) &\n",
    "                            (remote_data['gen_microcell'].isin(nearby_microcells))\n",
    "                        ].drop_duplicates(subset='serviceid')\n",
    "\n",
    "                        if not df_remote.empty:\n",
    "                            df_remote['origin'] = 'R'\n",
    "                            df_remote['currect_microcell'] = assessing_mic\n",
    "                            replicated_parts.append(df_remote)\n",
    "\n",
    "                df_microcell_replicated = pd.concat(replicated_parts, ignore_index=True)\n",
    "            else:\n",
    "                df_microcell_replicated = df_microcell.copy()\n",
    "\n",
    "            # -------- Local tampering (SPA) --------\n",
    "            spa_tampered_df = tampering.spa_tampering(\n",
    "                df_microcell_replicated,\n",
    "                type=tampering_type\n",
    "            )\n",
    "\n",
    "            # -------- Set TIMF data --------\n",
    "            data_service.set_local_data(spa_tampered_df.copy())\n",
    "\n",
    "            # --- Full remote pool (all other microcells) ---\n",
    "            # remote_data_set = full_df[full_df['gen_microcell'] != assessing_mic].copy()\n",
    "            # remote_data_set = full_df[full_df['gen_microcell'] != assessing_mic].copy()\n",
    "            remote_data_set = bma_tampered_df.copy()\n",
    "\n",
    "            \n",
    "    \n",
    "            rng = np.random.default_rng(42)  # fixed seed for reproducibility\n",
    "            uni_mic = remote_data_set['gen_microcell'].unique()\n",
    "\n",
    "            selected_mics = rng.choice(\n",
    "                uni_mic,\n",
    "                size=max(1, int(len(uni_mic) * 1)),\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            # --- Keep only records from selected microcells ---\n",
    "            remote_available = remote_data_set[remote_data_set['gen_microcell'].isin(selected_mics)].copy()\n",
    "\n",
    "            # --- Set remote data (partial availability) ---\n",
    "            data_service.set_remote_data(remote_available)\n",
    "\n",
    "            # print(spa_tampered_df.shape[0],bma_tampered_df.shape[0],df_microcell.shape[0]+bma_tampered_df.shape[0])\n",
    "\n",
    "            # if assessing_mic == 'M110':\n",
    "            microcell_data_all =pd.DataFrame()\n",
    "            for provider in df_microcell['providerid'].unique():\n",
    "                _, df_tda, time_df = timf.trust_assessment(provider, assessing_mic)\n",
    "                microcell_data_all= pd.concat([microcell_data_all, df_tda], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "            # print(microcell_data_all)\n",
    "\n",
    "            pred = sophistication.detect_sophistication(remaining_df, microcell_data_all.copy(), [0.3,0.1,0.2,0.1,0.1,0.2])\n",
    "\n",
    "            results_acc.append({\n",
    "                \"tampering_type\": tampering_type,\n",
    "                \"tampering_percentage\": tampering_percentage,\n",
    "                \"assessing_mic\": assessing_mic,\n",
    "                \"pred\": pred,\n",
    "                \"correct\": int(pred == tampering_type),\n",
    "            })\n",
    "\n",
    "\n",
    "            # if out == tampering_type:\n",
    "            #     print(\"correct\")\n",
    "            # else:\n",
    "            #     print(\"Error\")\n",
    "            #     # labels, maj, counts, centers_df = visualize_clusters_kmeans(out, k=3)\n",
    "            #     # print(\"Majority cluster:\", maj, \"size:\", counts[maj])\n",
    "            #     # print(\"Centers:\\n\", centers_df)\n",
    "\n",
    "                \n",
    "            #     # print(tampering_percentage,remote_data['true_label'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.DataFrame(results_acc)\n",
    "\n",
    "acc_by_type_pct = (\n",
    "    df_acc\n",
    "    .groupby([\"tampering_type\", \"tampering_percentage\"])[\"correct\"]\n",
    "    .mean()\n",
    "    .mul(100)\n",
    "    .reset_index(name=\"accuracy_%\")\n",
    "    .sort_values([\"tampering_type\", \"tampering_percentage\"])\n",
    ")\n",
    "\n",
    "print(acc_by_type_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e51999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def visualize_clusters_kmeans(new_df, k=3, random_state=0):\n",
    "    feats = ['Impact', 'Significance', 'Trend']\n",
    "    X = new_df[feats].to_numpy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=random_state)\n",
    "    labels = km.fit_predict(Xs)\n",
    "\n",
    "    # majority cluster\n",
    "    counts = np.bincount(labels)\n",
    "    maj = counts.argmax()\n",
    "\n",
    "    # centers back to original feature space\n",
    "    centers = scaler.inverse_transform(km.cluster_centers_)\n",
    "    centers_df = pd.DataFrame(centers, columns=feats)\n",
    "\n",
    "    # ---- Plot 1: Impact vs Trend ----\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(new_df['Impact'], new_df['Trend'], c=labels, alpha=0.7)\n",
    "    for ci, center in enumerate(centers):\n",
    "        plt.scatter(center[0], center[2], marker='X', s=200, edgecolors='black')\n",
    "        plt.text(center[0], center[2], f\"C{ci}\", ha='center')\n",
    "    plt.title(f'KMeans (k={k}) Impact vs Trend | Majority=C{maj} (n={counts[maj]})')\n",
    "    plt.xlabel('Impact')\n",
    "    plt.ylabel('Trend')\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Plot 2: Significance vs Trend ----\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(new_df['Significance'], new_df['Trend'], c=labels, alpha=0.7)\n",
    "    for ci, center in enumerate(centers):\n",
    "        plt.scatter(center[1], center[2], marker='X', s=200, edgecolors='black')\n",
    "        plt.text(center[1], center[2], f\"C{ci}\", ha='center')\n",
    "    plt.title(f'KMeans (k={k}) Significance vs Trend | Majority=C{maj} (n={counts[maj]})')\n",
    "    plt.xlabel('Significance')\n",
    "    plt.ylabel('Trend')\n",
    "    plt.show()\n",
    "\n",
    "    return labels, maj, counts, centers_df\n",
    "\n",
    "# Run it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "spa_tampered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db6853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc565a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b91f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv(\"tttt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fd77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4bd8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41dc057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b491bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87147739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ATTRS = ['speed', 'latency', 'bandwidth', 'coverage', 'reliability', 'security']\n",
    "\n",
    "\n",
    "class SophisticationDetector:\n",
    "    \"\"\"\n",
    "    Computes (Impact, Significance, Trend) scores for *detected tampered* records\n",
    "    and optionally classifies them into {Naive, Knowledgeable, Sophisticated}.\n",
    "\n",
    "    Key upgrade vs your previous version:\n",
    "      - adds percentile-based threshold calibration (fit_thresholds)\n",
    "      - supports automatic calibration inside detect() if thresholds not fitted yet\n",
    "      - safer handling of missing/invalid references\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        attrs=ATTRS,\n",
    "        microcell_col=\"gen_microcell\",\n",
    "        beta_low=0.0,\n",
    "        beta_high=5.0,\n",
    "        significance_mode=\"any_change\",   # any_change / positive_only / negative_only\n",
    "        impact_mode=\"magnitude\",          # magnitude / positive_only\n",
    "        q_impact_hi=0.80,\n",
    "        q_impact_mid=0.50,\n",
    "        q_sig_hi=0.80,\n",
    "        q_sig_mid=0.50,\n",
    "        q_trend_lo=0.30,\n",
    "        q_trend_mid=0.60,\n",
    "    ):\n",
    "        self.attrs = list(attrs)\n",
    "        self.microcell_col = microcell_col\n",
    "        self.beta_low = float(beta_low)\n",
    "        self.beta_high = float(beta_high)\n",
    "        self.significance_mode = significance_mode\n",
    "        self.impact_mode = impact_mode\n",
    "\n",
    "        # percentile hyperparams (you can tune these)\n",
    "        self.q_impact_hi = float(q_impact_hi)\n",
    "        self.q_impact_mid = float(q_impact_mid)\n",
    "        self.q_sig_hi = float(q_sig_hi)\n",
    "        self.q_sig_mid = float(q_sig_mid)\n",
    "        self.q_trend_lo = float(q_trend_lo)\n",
    "        self.q_trend_mid = float(q_trend_mid)\n",
    "\n",
    "        # thresholds will be learned via fit_thresholds()\n",
    "        self._thresholds_fitted = False\n",
    "        self.impact_hi = None\n",
    "        self.impact_mid = None\n",
    "        self.sig_hi = None\n",
    "        self.sig_mid = None\n",
    "        self.trend_lo = None\n",
    "        self.trend_mid = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Public API\n",
    "    # -----------------------------\n",
    "    def detect(\n",
    "        self,\n",
    "        correct_data: pd.DataFrame,\n",
    "        tampered_data: pd.DataFrame,\n",
    "        weight,\n",
    "        classify=True,\n",
    "        auto_fit_thresholds=True,\n",
    "        fit_scope=\"global\",  # \"global\" or \"per_microcell\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Returns dict: {microcell_id: df_scores}\n",
    "\n",
    "        auto_fit_thresholds:\n",
    "          - If classify=True and thresholds haven't been fitted yet,\n",
    "            auto_fit_thresholds=True will fit them using the scores produced in this call.\n",
    "        fit_scope:\n",
    "          - \"global\": fit thresholds once using all scores in this call\n",
    "          - \"per_microcell\": fit separate thresholds for each microcell (less stable; use only if needed)\n",
    "        \"\"\"\n",
    "        if tampered_data is None or tampered_data.empty:\n",
    "            return {}\n",
    "\n",
    "        df = tampered_data.copy()\n",
    "\n",
    "        # 1) only keep records that TDA flagged as tampered\n",
    "        if \"label\" not in df.columns:\n",
    "            raise ValueError(\"tampered_data must contain a 'label' column with 'T'/'C'.\")\n",
    "        df = df[df[\"label\"] == \"T\"].copy()\n",
    "        if df.empty:\n",
    "            return {}\n",
    "\n",
    "        # 2) ensure required columns exist\n",
    "        self._validate_columns(df, required=[\"providerid\", \"serviceid\", \"origin\", self.microcell_col] + self.attrs)\n",
    "        self._validate_columns(correct_data, required=[\"providerid\", \"serviceid\", self.microcell_col] + self.attrs)\n",
    "\n",
    "        # 3) compute scores per microcell (first pass, no labels yet)\n",
    "        out = {}\n",
    "        all_scores_for_fit = []\n",
    "\n",
    "        for mic_id, df_mic in df.groupby(self.microcell_col):\n",
    "            df_mic = df_mic.copy().reset_index(drop=True)\n",
    "\n",
    "            # Build D_* reference columns for BOTH origin types\n",
    "            df_mic = self._add_reference_columns(df_mic, correct_data, mic_id)\n",
    "\n",
    "            # Drop rows where reference could not be computed\n",
    "            for a in self.attrs:\n",
    "                df_mic = df_mic[pd.to_numeric(df_mic[f\"D_{a}\"], errors=\"coerce\").notna()]\n",
    "            if df_mic.empty:\n",
    "                continue\n",
    "\n",
    "            impact = self._compute_impact(df_mic, weight, mode=self.impact_mode)\n",
    "            significance = self._compute_significance(df_mic, weight, mode=self.significance_mode)\n",
    "            trend = self._compute_trend(df_mic, correct_data)\n",
    "\n",
    "            df_scores = pd.DataFrame({\n",
    "                \"Impact\": impact,\n",
    "                \"Significance\": significance,\n",
    "                \"Trend\": trend\n",
    "            })\n",
    "\n",
    "            df_scores = df_scores[pd.to_numeric(df_scores[\"Trend\"], errors=\"coerce\").notna()].reset_index(drop=True)\n",
    "            if df_scores.empty:\n",
    "                continue\n",
    "\n",
    "            out[mic_id] = df_scores\n",
    "\n",
    "            if fit_scope == \"global\":\n",
    "                all_scores_for_fit.append(df_scores)\n",
    "\n",
    "        # nothing to return\n",
    "        if not out:\n",
    "            return {}\n",
    "\n",
    "        # -----------------------------\n",
    "        # Threshold fitting + labeling\n",
    "        # -----------------------------\n",
    "        if classify:\n",
    "            if auto_fit_thresholds and not self._thresholds_fitted:\n",
    "                if fit_scope == \"global\":\n",
    "                    df_fit = pd.concat(all_scores_for_fit, ignore_index=True) if all_scores_for_fit else None\n",
    "                    if df_fit is None or df_fit.empty:\n",
    "                        # can't fit thresholds; fall back to \"Sophisticated\"\n",
    "                        for mic_id in out:\n",
    "                            out[mic_id][\"PredSoph\"] = \"Sophisticated\"\n",
    "                        return out\n",
    "                    self.fit_thresholds(df_fit)\n",
    "\n",
    "                elif fit_scope == \"per_microcell\":\n",
    "                    # Fit thresholds per microcell (less stable; optional)\n",
    "                    for mic_id, df_scores in out.items():\n",
    "                        self.fit_thresholds(df_scores)\n",
    "                        out[mic_id][\"PredSoph\"] = df_scores.apply(self._classify_row, axis=1)\n",
    "                    return out\n",
    "\n",
    "            # If still not fitted (e.g., auto_fit_thresholds=False), you must call fit_thresholds() manually\n",
    "            if not self._thresholds_fitted:\n",
    "                raise RuntimeError(\n",
    "                    \"Thresholds not fitted. Call fit_thresholds(df_scores) first, \"\n",
    "                    \"or set auto_fit_thresholds=True.\"\n",
    "                )\n",
    "\n",
    "            # Apply classification using fitted thresholds\n",
    "            for mic_id, df_scores in out.items():\n",
    "                df_scores[\"PredSoph\"] = df_scores.apply(self._classify_row, axis=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # -----------------------------\n",
    "    # Reference building (D_* columns)\n",
    "    # -----------------------------\n",
    "    def _add_reference_columns(self, df_mic: pd.DataFrame, correct_data: pd.DataFrame, mic_id):\n",
    "        \"\"\"\n",
    "        Creates D_speed..D_security columns:\n",
    "          - origin == 'R': D_* = origin record values matched by serviceid from correct_data\n",
    "          - origin == 'G': D_* = provider mean from correct_data excluding this microcell\n",
    "        \"\"\"\n",
    "        df_mic = df_mic.copy()\n",
    "\n",
    "        for a in self.attrs:\n",
    "            df_mic[f\"D_{a}\"] = np.nan\n",
    "\n",
    "        # origin == 'R': match by serviceid\n",
    "        mask_r = (df_mic[\"origin\"] == \"R\")\n",
    "        if mask_r.any():\n",
    "            ref_r = correct_data.drop_duplicates(subset=[\"serviceid\"]).set_index(\"serviceid\")\n",
    "            for a in self.attrs:\n",
    "                df_mic.loc[mask_r, f\"D_{a}\"] = df_mic.loc[mask_r, \"serviceid\"].map(ref_r[a])\n",
    "\n",
    "        # origin == 'G': provider mean excluding this microcell\n",
    "        mask_g = (df_mic[\"origin\"] == \"G\")\n",
    "        if mask_g.any():\n",
    "            for idx in df_mic.index[mask_g]:\n",
    "                prov = df_mic.at[idx, \"providerid\"]\n",
    "                provider_other = correct_data[\n",
    "                    (correct_data[\"providerid\"] == prov) &\n",
    "                    (correct_data[self.microcell_col] != mic_id)\n",
    "                ]\n",
    "\n",
    "                if provider_other.shape[0] < 2:\n",
    "                    continue\n",
    "\n",
    "                mean_vals = provider_other[self.attrs].mean()\n",
    "                for a in self.attrs:\n",
    "                    df_mic.at[idx, f\"D_{a}\"] = mean_vals[a]\n",
    "\n",
    "        return df_mic\n",
    "\n",
    "    # -----------------------------\n",
    "    # Core scoring functions\n",
    "    # -----------------------------\n",
    "    def _compute_delta(self, df):\n",
    "        A = df[self.attrs].to_numpy(float)\n",
    "        D = df[[f\"D_{a}\" for a in self.attrs]].to_numpy(float)\n",
    "        return A - D\n",
    "\n",
    "    def _compute_impact(self, df, weight, mode=\"magnitude\"):\n",
    "        delta = self._compute_delta(df)\n",
    "        w = np.array(weight, dtype=float)\n",
    "\n",
    "        if w.size != len(self.attrs):\n",
    "            raise ValueError(f\"weight must have length {len(self.attrs)} to match attrs.\")\n",
    "\n",
    "        if mode == \"positive_only\":\n",
    "            delta = np.clip(delta, 0, None)\n",
    "        else:\n",
    "            delta = np.abs(delta)\n",
    "\n",
    "        return (delta * w).sum(axis=1)\n",
    "\n",
    "    def _compute_significance(self, df, weight, mode=\"any_change\"):\n",
    "        delta = self._compute_delta(df)\n",
    "        w = np.array(weight, dtype=float)\n",
    "\n",
    "        if mode == \"positive_only\":\n",
    "            changed = (delta > 0).astype(int)\n",
    "        elif mode == \"negative_only\":\n",
    "            changed = (delta < 0).astype(int)\n",
    "        else:\n",
    "            changed = (np.abs(delta) > 0).astype(int)\n",
    "\n",
    "        num_changed = changed.sum(axis=1)\n",
    "        num_changed = np.maximum(num_changed, 1)\n",
    "\n",
    "        sig = (changed * w).sum(axis=1) / num_changed\n",
    "        return sig\n",
    "\n",
    "    def _compute_trend(self, df, correct_df):\n",
    "        \"\"\"\n",
    "        Trend = 1 - (distance from provider mean) / (max possible distance)\n",
    "        \"\"\"\n",
    "        out = np.full(len(df), np.nan, dtype=float)\n",
    "\n",
    "        k = len(self.attrs)\n",
    "        max_d = np.sqrt(k) * (self.beta_high - self.beta_low)\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            prov = df.iloc[i][\"providerid\"]\n",
    "            sid = df.iloc[i][\"serviceid\"]\n",
    "\n",
    "            temp = correct_df[(correct_df[\"providerid\"] == prov) & (correct_df[\"serviceid\"] != sid)]\n",
    "            if temp.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            mean_vec = temp[self.attrs].to_numpy(float).mean(axis=0)\n",
    "            rec_vec = df.iloc[i][self.attrs].to_numpy(float)\n",
    "\n",
    "            d = float(np.linalg.norm(rec_vec - mean_vec))\n",
    "            out[i] = max(0.0, min(1.0, 1.0 - d / max_d))\n",
    "\n",
    "        return out\n",
    "\n",
    "    # -----------------------------\n",
    "    # Threshold fitting + classification\n",
    "    # -----------------------------\n",
    "    def fit_thresholds(self, df_scores: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Fit thresholds from score distributions (percentile-based).\n",
    "        Call once on a representative batch of scores.\n",
    "        \"\"\"\n",
    "        if df_scores is None or df_scores.empty:\n",
    "            raise ValueError(\"df_scores is empty; cannot fit thresholds.\")\n",
    "\n",
    "        df_scores = df_scores.copy()\n",
    "        for c in [\"Impact\", \"Significance\", \"Trend\"]:\n",
    "            df_scores[c] = pd.to_numeric(df_scores[c], errors=\"coerce\")\n",
    "        df_scores = df_scores.dropna(subset=[\"Impact\", \"Significance\", \"Trend\"])\n",
    "        if df_scores.empty:\n",
    "            raise ValueError(\"df_scores has no valid numeric rows after cleaning.\")\n",
    "\n",
    "        self.impact_hi = float(df_scores[\"Impact\"].quantile(self.q_impact_hi))\n",
    "        self.impact_mid = float(df_scores[\"Impact\"].quantile(self.q_impact_mid))\n",
    "\n",
    "        self.sig_hi = float(df_scores[\"Significance\"].quantile(self.q_sig_hi))\n",
    "        self.sig_mid = float(df_scores[\"Significance\"].quantile(self.q_sig_mid))\n",
    "\n",
    "        self.trend_lo = float(df_scores[\"Trend\"].quantile(self.q_trend_lo))\n",
    "        self.trend_mid = float(df_scores[\"Trend\"].quantile(self.q_trend_mid))\n",
    "\n",
    "        self._thresholds_fitted = True\n",
    "\n",
    "    def _classify_row(self, row):\n",
    "        impact = float(row[\"Impact\"])\n",
    "        sig = float(row[\"Significance\"])\n",
    "        trend = float(row[\"Trend\"])\n",
    "\n",
    "        # Naive: large impact + many changed attributes + low mimicry (low trend)\n",
    "        if impact >= self.impact_hi and sig >= self.sig_hi and trend <= self.trend_lo:\n",
    "            return \"Naive\"\n",
    "\n",
    "        # Knowledgeable: moderate impact/significance + medium mimicry\n",
    "        if impact >= self.impact_mid and sig >= self.sig_mid and trend <= self.trend_mid:\n",
    "            return \"Knowledgeable\"\n",
    "\n",
    "        return \"Sophisticated\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validation\n",
    "    # -----------------------------\n",
    "    @staticmethod\n",
    "    def _validate_columns(df, required):\n",
    "        missing = [c for c in required if c not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required columns: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evaluations.evaluation_data.evaluation_data import EvaluationData\n",
    "from tampering.tampering import Tampering\n",
    "from timf.timf import TIMF\n",
    "from data_service.data_service import DataService\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ============================================================\n",
    "# SophisticationDetector (as defined by you) must be available\n",
    "# ============================================================\n",
    "# (Paste the SophisticationDetector class ABOVE this cell)\n",
    "\n",
    "# ============================================================\n",
    "# Setup\n",
    "# ============================================================\n",
    "evaluation_data = EvaluationData()\n",
    "tampering = Tampering()\n",
    "\n",
    "data_service = DataService()\n",
    "timf = TIMF(data_service)\n",
    "\n",
    "data = evaluation_data.get_data()\n",
    "\n",
    "tampering_percentages = list(range(10, 100, 20))  # 10,30,50,70,90\n",
    "tampering_types = [\"N\", \"K\", \"S\"]  # Naive, Knowledgeable, Sophisticated\n",
    "\n",
    "WEIGHTS = [0.3, 0.1, 0.2, 0.1, 0.1, 0.2]\n",
    "TRUE_MAP = {\"N\": \"Naive\", \"K\": \"Knowledgeable\", \"S\": \"Sophisticated\"}\n",
    "\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371.0 * c\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Instantiate sophistication module\n",
    "# IMPORTANT: microcell_col must match df_tda column name\n",
    "# ============================================================\n",
    "soph = SophisticationDetector(\n",
    "    microcell_col=\"gen_microcell\",      # change to \"currect_microcell\" if needed\n",
    "    impact_mode=\"magnitude\",            # works for SPA + BMA\n",
    "    significance_mode=\"any_change\"      # works for SPA + BMA\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Run Experiment\n",
    "# ============================================================\n",
    "soph_rows = []\n",
    "\n",
    "for tampering_type in tampering_types:\n",
    "    for tampering_percentage in tampering_percentages:\n",
    "\n",
    "        print(f\"Experiment: Type={tampering_type}, Percentage={tampering_percentage}%\")\n",
    "\n",
    "        for assessing_mic in data[\"gen_microcell\"].unique():\n",
    "\n",
    "            df_microcell = data[data[\"gen_microcell\"] == assessing_mic]\n",
    "\n",
    "            # -------- Remote tampering (BMA) --------\n",
    "            bma_tampered_df = tampering.bma_tampering(\n",
    "                data[data[\"gen_microcell\"] != assessing_mic].reset_index(drop=True),\n",
    "                tampering_percentage,\n",
    "                tampering_type\n",
    "            )\n",
    "            remote_data = bma_tampered_df.copy()\n",
    "\n",
    "            # -------- Replication logic --------\n",
    "            microcell_coords = data.groupby(\"gen_microcell\")[[\"latitude\", \"longitude\"]].first().reset_index()\n",
    "            current_coords = microcell_coords[microcell_coords[\"gen_microcell\"] == assessing_mic]\n",
    "\n",
    "            if not current_coords.empty:\n",
    "                lat1 = current_coords[\"latitude\"].values[0]\n",
    "                lon1 = current_coords[\"longitude\"].values[0]\n",
    "\n",
    "                df_microcell_part = df_microcell.copy()\n",
    "                df_microcell_part.loc[:, \"currect_microcell\"] = assessing_mic\n",
    "\n",
    "                replicated_parts = [df_microcell_part]\n",
    "\n",
    "                for provider_id in df_microcell[\"providerid\"].unique():\n",
    "\n",
    "                    provider_remote = remote_data[remote_data[\"providerid\"] == provider_id]\n",
    "                    candidate_microcells = []\n",
    "\n",
    "                    for _, row in microcell_coords.iterrows():\n",
    "                        if row[\"gen_microcell\"] == assessing_mic:\n",
    "                            continue\n",
    "                        if (provider_remote[\"gen_microcell\"] == row[\"gen_microcell\"]).any():\n",
    "                            dist = _haversine_km(lat1, lon1, row[\"latitude\"], row[\"longitude\"])\n",
    "                            candidate_microcells.append((row[\"gen_microcell\"], dist))\n",
    "\n",
    "                    candidate_microcells.sort(key=lambda x: x[1])\n",
    "                    nearby_microcells = [m for m, _ in candidate_microcells[:10]]\n",
    "\n",
    "                    if nearby_microcells:\n",
    "                        df_remote = remote_data[\n",
    "                            (remote_data[\"providerid\"] == provider_id) &\n",
    "                            (remote_data[\"gen_microcell\"].isin(nearby_microcells))\n",
    "                        ].drop_duplicates(subset=\"serviceid\")\n",
    "\n",
    "                        if not df_remote.empty:\n",
    "                            df_remote[\"origin\"] = \"R\"\n",
    "                            df_remote[\"currect_microcell\"] = assessing_mic\n",
    "                            replicated_parts.append(df_remote)\n",
    "\n",
    "                df_microcell_replicated = pd.concat(replicated_parts, ignore_index=True)\n",
    "            else:\n",
    "                df_microcell_replicated = df_microcell.copy()\n",
    "\n",
    "            # -------- Local tampering (SPA) --------\n",
    "            spa_tampered_df = tampering.spa_tampering(df_microcell_replicated, type=tampering_type)\n",
    "\n",
    "            # -------- Set TIMF local data --------\n",
    "            data_service.set_local_data(spa_tampered_df.copy())\n",
    "\n",
    "            # --- Remote availability pool ---\n",
    "            remote_data_set = data[data[\"gen_microcell\"] != assessing_mic].copy()\n",
    "\n",
    "            rng = np.random.default_rng(42)\n",
    "            uni_mic = remote_data_set[\"gen_microcell\"].unique()\n",
    "\n",
    "            selected_mics = rng.choice(\n",
    "                uni_mic,\n",
    "                size=max(1, int(len(uni_mic) * 0.8)),\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            remote_available = remote_data_set[remote_data_set[\"gen_microcell\"].isin(selected_mics)].copy()\n",
    "            data_service.set_remote_data(remote_available)\n",
    "\n",
    "            # =====================================================\n",
    "            # Run per-provider: TDA -> Sophistication\n",
    "            # =====================================================\n",
    "            for provider in df_microcell[\"providerid\"].unique():\n",
    "\n",
    "                _, df_tda, _ = timf.trust_assessment(provider, assessing_mic)\n",
    "                if df_tda is None or df_tda.empty:\n",
    "                    continue\n",
    "\n",
    "                # ---------- Sophistication ----------\n",
    "                # Use remote_available as \"correct_data\" reference\n",
    "                # Recompute without classification first\n",
    "# easiest way: just fit using current df_soph_all scores\n",
    "\n",
    "                soph_out = soph.detect(\n",
    "                    correct_data=remote_available,\n",
    "                    tampered_data=df_tda,\n",
    "                    weight=WEIGHTS,\n",
    "                    classify=True\n",
    "                )\n",
    "\n",
    "                for mic_id, df_scores in soph_out.items():\n",
    "                    if df_scores is None or df_scores.empty:\n",
    "                        continue\n",
    "\n",
    "                    df_scores = df_scores.copy()\n",
    "                    df_scores[\"assessing_microcell\"] = assessing_mic\n",
    "                    df_scores[\"microcell_key\"] = mic_id\n",
    "                    df_scores[\"providerid\"] = provider\n",
    "                    df_scores[\"tampering_type\"] = tampering_type\n",
    "                    df_scores[\"tampering_percentage\"] = tampering_percentage\n",
    "                    df_scores[\"TrueSoph\"] = TRUE_MAP[tampering_type]\n",
    "\n",
    "                    soph_rows.append(df_scores)\n",
    "\n",
    "# ============================================================\n",
    "# Aggregate + Evaluate\n",
    "# ============================================================\n",
    "if len(soph_rows) == 0:\n",
    "    raise RuntimeError(\"No sophistication outputs produced. Check df_tda columns and labels.\")\n",
    "\n",
    "df_soph_all = pd.concat(soph_rows, ignore_index=True)\n",
    "\n",
    "soph.fit_thresholds(df_soph_all)\n",
    "\n",
    "# Re-label with new thresholds\n",
    "df_soph_all['PredSoph'] = df_soph_all.apply(soph._classify_row, axis=1)\n",
    "\n",
    "\n",
    "overall_acc = accuracy_score(df_soph_all[\"TrueSoph\"], df_soph_all[\"PredSoph\"])\n",
    "print(\"\\nOverall sophistication accuracy:\", overall_acc)\n",
    "\n",
    "labels = [\"Naive\", \"Knowledgeable\", \"Sophisticated\"]\n",
    "cm = confusion_matrix(df_soph_all[\"TrueSoph\"], df_soph_all[\"PredSoph\"], labels=labels)\n",
    "print(\"\\nConfusion matrix rows=True, cols=Pred:\\n\", cm)\n",
    "\n",
    "acc_by_pct = (\n",
    "    df_soph_all.assign(correct=(df_soph_all[\"TrueSoph\"] == df_soph_all[\"PredSoph\"]).astype(int))\n",
    "    .groupby([\"tampering_percentage\"])[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "print(\"\\nAccuracy by tampering percentage:\\n\", acc_by_pct)\n",
    "\n",
    "# ============================================================\n",
    "# Plots\n",
    "# ============================================================\n",
    "\n",
    "# 1) Impact vs Trend scatter (colored by PredSoph)\n",
    "plt.figure(figsize=(6, 4))\n",
    "for lab in labels:\n",
    "    sub = df_soph_all[df_soph_all[\"PredSoph\"] == lab]\n",
    "    plt.scatter(sub[\"Impact\"], sub[\"Trend\"], alpha=0.55, label=lab)\n",
    "\n",
    "plt.xlabel(\"Impact\")\n",
    "plt.ylabel(\"Trend\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Accuracy vs tampering percentage\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(acc_by_pct[\"tampering_percentage\"], acc_by_pct[\"accuracy\"], marker=\"o\")\n",
    "plt.xlabel(\"Tampering Percentage (%)\")\n",
    "plt.ylabel(\"Sophistication Classification Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Histograms\n",
    "for col in [\"Impact\", \"Significance\", \"Trend\"]:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df_soph_all[col].astype(float).values, bins=30, alpha=0.7)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d2860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073033e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb49a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17cea9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e790d0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9840df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417f894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb50b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e683b188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evaluations.evaluation_data.evaluation_data import EvaluationData\n",
    "from tampering.tampering import Tampering\n",
    "from timf.timf import TIMF\n",
    "from data_service.data_service import DataService\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ============================================================\n",
    "# SophisticationDetector (as defined by you) must be available\n",
    "# ============================================================\n",
    "# (Paste the SophisticationDetector class ABOVE this cell)\n",
    "\n",
    "# ============================================================\n",
    "# Setup\n",
    "# ============================================================\n",
    "evaluation_data = EvaluationData()\n",
    "tampering = Tampering()\n",
    "\n",
    "data_service = DataService()\n",
    "timf = TIMF(data_service)\n",
    "\n",
    "data = evaluation_data.get_data()\n",
    "\n",
    "tampering_percentages = list(range(10, 100, 20))  # 10,30,50,70,90\n",
    "tampering_types = [\"N\", \"K\", \"S\"]  # Naive, Knowledgeable, Sophisticated\n",
    "\n",
    "WEIGHTS = [0.3, 0.1, 0.2, 0.1, 0.1, 0.2]\n",
    "TRUE_MAP = {\"N\": \"Naive\", \"K\": \"Knowledgeable\", \"S\": \"Sophisticated\"}\n",
    "\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371.0 * c\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Instantiate sophistication module\n",
    "# IMPORTANT: microcell_col must match df_tda column name\n",
    "# ============================================================\n",
    "soph = SophisticationDetector(\n",
    "    microcell_col=\"gen_microcell\",      # change to \"currect_microcell\" if needed\n",
    "    impact_mode=\"magnitude\",            # works for SPA + BMA\n",
    "    significance_mode=\"any_change\"      # works for SPA + BMA\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Run Experiment\n",
    "# ============================================================\n",
    "soph_rows = []\n",
    "\n",
    "for tampering_type in tampering_types:\n",
    "    for tampering_percentage in tampering_percentages:\n",
    "\n",
    "        print(f\"Experiment: Type={tampering_type}, Percentage={tampering_percentage}%\")\n",
    "\n",
    "        for assessing_mic in data[\"gen_microcell\"].unique():\n",
    "\n",
    "            df_microcell = data[data[\"gen_microcell\"] == assessing_mic]\n",
    "\n",
    "            # -------- Remote tampering (BMA) --------\n",
    "            bma_tampered_df = tampering.bma_tampering(\n",
    "                data[data[\"gen_microcell\"] != assessing_mic].reset_index(drop=True),\n",
    "                tampering_percentage,\n",
    "                tampering_type\n",
    "            )\n",
    "            remote_data = bma_tampered_df.copy()\n",
    "\n",
    "            # -------- Replication logic --------\n",
    "            microcell_coords = data.groupby(\"gen_microcell\")[[\"latitude\", \"longitude\"]].first().reset_index()\n",
    "            current_coords = microcell_coords[microcell_coords[\"gen_microcell\"] == assessing_mic]\n",
    "\n",
    "            if not current_coords.empty:\n",
    "                lat1 = current_coords[\"latitude\"].values[0]\n",
    "                lon1 = current_coords[\"longitude\"].values[0]\n",
    "\n",
    "                df_microcell_part = df_microcell.copy()\n",
    "                df_microcell_part.loc[:, \"currect_microcell\"] = assessing_mic\n",
    "\n",
    "                replicated_parts = [df_microcell_part]\n",
    "\n",
    "                for provider_id in df_microcell[\"providerid\"].unique():\n",
    "\n",
    "                    provider_remote = remote_data[remote_data[\"providerid\"] == provider_id]\n",
    "                    candidate_microcells = []\n",
    "\n",
    "                    for _, row in microcell_coords.iterrows():\n",
    "                        if row[\"gen_microcell\"] == assessing_mic:\n",
    "                            continue\n",
    "                        if (provider_remote[\"gen_microcell\"] == row[\"gen_microcell\"]).any():\n",
    "                            dist = _haversine_km(lat1, lon1, row[\"latitude\"], row[\"longitude\"])\n",
    "                            candidate_microcells.append((row[\"gen_microcell\"], dist))\n",
    "\n",
    "                    candidate_microcells.sort(key=lambda x: x[1])\n",
    "                    nearby_microcells = [m for m, _ in candidate_microcells[:10]]\n",
    "\n",
    "                    if nearby_microcells:\n",
    "                        df_remote = remote_data[\n",
    "                            (remote_data[\"providerid\"] == provider_id) &\n",
    "                            (remote_data[\"gen_microcell\"].isin(nearby_microcells))\n",
    "                        ].drop_duplicates(subset=\"serviceid\")\n",
    "\n",
    "                        if not df_remote.empty:\n",
    "                            df_remote[\"origin\"] = \"R\"\n",
    "                            df_remote[\"currect_microcell\"] = assessing_mic\n",
    "                            replicated_parts.append(df_remote)\n",
    "\n",
    "                df_microcell_replicated = pd.concat(replicated_parts, ignore_index=True)\n",
    "            else:\n",
    "                df_microcell_replicated = df_microcell.copy()\n",
    "\n",
    "            # -------- Local tampering (SPA) --------\n",
    "            spa_tampered_df = tampering.spa_tampering(df_microcell_replicated, type=tampering_type)\n",
    "\n",
    "            # -------- Set TIMF local data --------\n",
    "            data_service.set_local_data(spa_tampered_df.copy())\n",
    "\n",
    "            # --- Remote availability pool ---\n",
    "            remote_data_set = data[data[\"gen_microcell\"] != assessing_mic].copy()\n",
    "\n",
    "            rng = np.random.default_rng(42)\n",
    "            uni_mic = remote_data_set[\"gen_microcell\"].unique()\n",
    "\n",
    "            selected_mics = rng.choice(\n",
    "                uni_mic,\n",
    "                size=max(1, int(len(uni_mic) * 0.8)),\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            remote_available = remote_data_set[remote_data_set[\"gen_microcell\"].isin(selected_mics)].copy()\n",
    "            data_service.set_remote_data(remote_available)\n",
    "\n",
    "            # =====================================================\n",
    "            # Run per-provider: TDA -> Sophistication\n",
    "            # =====================================================\n",
    "            for provider in df_microcell[\"providerid\"].unique():\n",
    "\n",
    "                _, df_tda, _ = timf.trust_assessment(provider, assessing_mic)\n",
    "                if df_tda is None or df_tda.empty:\n",
    "                    continue\n",
    "\n",
    "                # ---------- Sophistication ----------\n",
    "                # Use remote_available as \"correct_data\" reference\n",
    "                soph_out = soph.detect(\n",
    "                    correct_data=remote_available,\n",
    "                    tampered_data=df_tda,\n",
    "                    weight=WEIGHTS,\n",
    "                    classify=True\n",
    "                )\n",
    "\n",
    "                for mic_id, df_scores in soph_out.items():\n",
    "                    if df_scores is None or df_scores.empty:\n",
    "                        continue\n",
    "\n",
    "                    df_scores = df_scores.copy()\n",
    "                    df_scores[\"assessing_microcell\"] = assessing_mic\n",
    "                    df_scores[\"microcell_key\"] = mic_id\n",
    "                    df_scores[\"providerid\"] = provider\n",
    "                    df_scores[\"tampering_type\"] = tampering_type\n",
    "                    df_scores[\"tampering_percentage\"] = tampering_percentage\n",
    "                    df_scores[\"TrueSoph\"] = TRUE_MAP[tampering_type]\n",
    "\n",
    "                    soph_rows.append(df_scores)\n",
    "\n",
    "# ============================================================\n",
    "# Aggregate + Evaluate\n",
    "# ============================================================\n",
    "if len(soph_rows) == 0:\n",
    "    raise RuntimeError(\"No sophistication outputs produced. Check df_tda columns and labels.\")\n",
    "\n",
    "df_soph_all = pd.concat(soph_rows, ignore_index=True)\n",
    "\n",
    "overall_acc = accuracy_score(df_soph_all[\"TrueSoph\"], df_soph_all[\"PredSoph\"])\n",
    "print(\"\\nOverall sophistication accuracy:\", overall_acc)\n",
    "\n",
    "labels = [\"Naive\", \"Knowledgeable\", \"Sophisticated\"]\n",
    "cm = confusion_matrix(df_soph_all[\"TrueSoph\"], df_soph_all[\"PredSoph\"], labels=labels)\n",
    "print(\"\\nConfusion matrix rows=True, cols=Pred:\\n\", cm)\n",
    "\n",
    "acc_by_pct = (\n",
    "    df_soph_all.assign(correct=(df_soph_all[\"TrueSoph\"] == df_soph_all[\"PredSoph\"]).astype(int))\n",
    "    .groupby([\"tampering_percentage\"])[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "print(\"\\nAccuracy by tampering percentage:\\n\", acc_by_pct)\n",
    "\n",
    "# ============================================================\n",
    "# Plots\n",
    "# ============================================================\n",
    "\n",
    "# 1) Impact vs Trend scatter (colored by PredSoph)\n",
    "plt.figure(figsize=(6, 4))\n",
    "for lab in labels:\n",
    "    sub = df_soph_all[df_soph_all[\"PredSoph\"] == lab]\n",
    "    plt.scatter(sub[\"Impact\"], sub[\"Trend\"], alpha=0.55, label=lab)\n",
    "\n",
    "plt.xlabel(\"Impact\")\n",
    "plt.ylabel(\"Trend\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Accuracy vs tampering percentage\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(acc_by_pct[\"tampering_percentage\"], acc_by_pct[\"accuracy\"], marker=\"o\")\n",
    "plt.xlabel(\"Tampering Percentage (%)\")\n",
    "plt.ylabel(\"Sophistication Classification Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Histograms\n",
    "for col in [\"Impact\", \"Significance\", \"Trend\"]:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(df_soph_all[col].astype(float).values, bins=30, alpha=0.7)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evaluations.evaluation_data.evaluation_data import EvaluationData\n",
    "from tampering.tampering import Tampering\n",
    "from timf.timf import TIMF\n",
    "from data_service.data_service import DataService\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# ============================================================\n",
    "# Setup\n",
    "# ============================================================\n",
    "evaluation_data = EvaluationData()\n",
    "tampering = Tampering()\n",
    "\n",
    "data_service = DataService()\n",
    "timf = TIMF(data_service)\n",
    "\n",
    "data = evaluation_data.get_data()\n",
    "\n",
    "# You already have this class in your project\n",
    "sophistication = SophisticationDetector()\n",
    "\n",
    "tampering_percentages = list(range(10, 100, 20))  # 10,30,50,70,90\n",
    "tampering_types = [\"N\", \"K\", \"S\"]  # Naive, Knowledgeable, Sophisticated\n",
    "\n",
    "WEIGHTS = [0.3, 0.1, 0.2, 0.1, 0.1, 0.2]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371.0 * c\n",
    "\n",
    "\n",
    "def classify_sophistication(row):\n",
    "    \"\"\"\n",
    "    Rule-based mapping from (Impact, Significance, Trend) -> class label.\n",
    "    Adjust thresholds as needed after you see distributions.\n",
    "    \"\"\"\n",
    "    impact = float(row[\"Impact\"])\n",
    "    sig = float(row[\"Significance\"])\n",
    "    trend = float(row[\"Trend\"])\n",
    "\n",
    "    # Example rules (simple + explainable)\n",
    "    # Naive: high impact & significant changes but poor trend mimicry\n",
    "    if impact >= 0.60 and sig >= 0.60 and trend <= 0.45:\n",
    "        return \"Naive\"\n",
    "\n",
    "    # Knowledgeable: moderate impact/significance, some mimicry but not strong\n",
    "    if impact >= 0.35 and sig >= 0.35 and trend <= 0.65:\n",
    "        return \"Knowledgeable\"\n",
    "\n",
    "    # Sophisticated: lower/controlled impact + trend-aligned (mimicking)\n",
    "    return \"Sophisticated\"\n",
    "\n",
    "\n",
    "TRUE_MAP = {\"N\": \"Naive\", \"K\": \"Knowledgeable\", \"S\": \"Sophisticated\"}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main experiment: run TDA -> run sophistication on detected T records\n",
    "# ============================================================\n",
    "soph_results = []  # will store record-level sophistication outputs\n",
    "\n",
    "for tampering_type in tampering_types:\n",
    "    for tampering_percentage in tampering_percentages:\n",
    "\n",
    "        print(f\"Experiment: Tampering Type={tampering_type}, Percentage={tampering_percentage}%\")\n",
    "\n",
    "        for assessing_mic in data[\"gen_microcell\"].unique():\n",
    "\n",
    "            df_microcell = data[data[\"gen_microcell\"] == assessing_mic]\n",
    "\n",
    "            # -------- Remote tampering (BMA) --------\n",
    "            bma_tampered_df = tampering.bma_tampering(\n",
    "                data[data[\"gen_microcell\"] != assessing_mic].reset_index(drop=True),\n",
    "                tampering_percentage,\n",
    "                tampering_type\n",
    "            )\n",
    "            remote_data = bma_tampered_df.copy()\n",
    "\n",
    "            # -------- Replication logic --------\n",
    "            microcell_coords = data.groupby(\"gen_microcell\")[[\"latitude\", \"longitude\"]].first().reset_index()\n",
    "            current_coords = microcell_coords[microcell_coords[\"gen_microcell\"] == assessing_mic]\n",
    "\n",
    "            if not current_coords.empty:\n",
    "                lat1 = current_coords[\"latitude\"].values[0]\n",
    "                lon1 = current_coords[\"longitude\"].values[0]\n",
    "\n",
    "                df_microcell_part = df_microcell.copy()\n",
    "                df_microcell_part.loc[:, \"currect_microcell\"] = assessing_mic\n",
    "\n",
    "                replicated_parts = [df_microcell_part]\n",
    "\n",
    "                for provider_id in df_microcell[\"providerid\"].unique():\n",
    "\n",
    "                    provider_remote = remote_data[remote_data[\"providerid\"] == provider_id]\n",
    "                    candidate_microcells = []\n",
    "\n",
    "                    for _, row in microcell_coords.iterrows():\n",
    "                        if row[\"gen_microcell\"] == assessing_mic:\n",
    "                            continue\n",
    "                        if (provider_remote[\"gen_microcell\"] == row[\"gen_microcell\"]).any():\n",
    "                            dist = _haversine_km(lat1, lon1, row[\"latitude\"], row[\"longitude\"])\n",
    "                            candidate_microcells.append((row[\"gen_microcell\"], dist))\n",
    "\n",
    "                    candidate_microcells.sort(key=lambda x: x[1])\n",
    "                    nearby_microcells = [m for m, _ in candidate_microcells[:10]]\n",
    "\n",
    "                    if nearby_microcells:\n",
    "                        df_remote = remote_data[\n",
    "                            (remote_data[\"providerid\"] == provider_id) &\n",
    "                            (remote_data[\"gen_microcell\"].isin(nearby_microcells))\n",
    "                        ].drop_duplicates(subset=\"serviceid\")\n",
    "\n",
    "                        if not df_remote.empty:\n",
    "                            df_remote[\"origin\"] = \"R\"\n",
    "                            df_remote[\"currect_microcell\"] = assessing_mic\n",
    "                            replicated_parts.append(df_remote)\n",
    "\n",
    "                df_microcell_replicated = pd.concat(replicated_parts, ignore_index=True)\n",
    "            else:\n",
    "                df_microcell_replicated = df_microcell.copy()\n",
    "\n",
    "            # -------- Local tampering (SPA) --------\n",
    "            spa_tampered_df = tampering.spa_tampering(\n",
    "                df_microcell_replicated,\n",
    "                type=tampering_type\n",
    "            )\n",
    "\n",
    "            # -------- Set TIMF data --------\n",
    "            data_service.set_local_data(spa_tampered_df.copy())\n",
    "\n",
    "            # --- Full remote pool (all other microcells) ---\n",
    "            remote_data_set = data[data[\"gen_microcell\"] != assessing_mic].copy()\n",
    "\n",
    "            # --- Select 80% of microcells (availability by microcell) ---\n",
    "            rng = np.random.default_rng(42)\n",
    "            uni_mic = remote_data_set[\"gen_microcell\"].unique()\n",
    "\n",
    "            selected_mics = rng.choice(\n",
    "                uni_mic,\n",
    "                size=max(1, int(len(uni_mic) * 0.8)),\n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            remote_available = remote_data_set[remote_data_set[\"gen_microcell\"].isin(selected_mics)].copy()\n",
    "            data_service.set_remote_data(remote_available)\n",
    "\n",
    "            # =====================================================\n",
    "            # Run per-provider\n",
    "            # =====================================================\n",
    "            for provider in df_microcell[\"providerid\"].unique():\n",
    "\n",
    "                # ---------- TDA ----------\n",
    "                # returns: (something, df_tda, time_df)\n",
    "                _, df_tda, _ = timf.trust_assessment(provider, assessing_mic)\n",
    "\n",
    "                if df_tda is None or df_tda.empty:\n",
    "                    continue\n",
    "\n",
    "                # ---------- Sophistication (only on detected tampered rows inside Sophistication class) ----------\n",
    "                soph_out = sophistication.detect_sophistication(\n",
    "                    correct_data=df_microcell_replicated,  # reference set\n",
    "                    tampered_data=df_tda,                  # output of TDA (must have label/origin)\n",
    "                    weight=WEIGHTS\n",
    "                )\n",
    "\n",
    "                # soph_out is a dict: {microcell_id: df(Impact,Significance,Trend), ...}\n",
    "                for mic_id, df_soph in soph_out.items():\n",
    "                    if df_soph is None or df_soph.empty:\n",
    "                        continue\n",
    "\n",
    "                    df_soph = df_soph.copy()\n",
    "                    df_soph[\"assessing_microcell\"] = assessing_mic\n",
    "                    df_soph[\"microcell_key\"] = mic_id\n",
    "                    df_soph[\"providerid\"] = provider\n",
    "                    df_soph[\"tampering_type\"] = tampering_type\n",
    "                    df_soph[\"tampering_percentage\"] = tampering_percentage\n",
    "                    df_soph[\"TrueSoph\"] = TRUE_MAP[tampering_type]\n",
    "\n",
    "                    soph_results.append(df_soph)\n",
    "\n",
    "# ============================================================\n",
    "# Aggregate outputs\n",
    "# ============================================================\n",
    "if len(soph_results) == 0:\n",
    "    raise RuntimeError(\"No sophistication outputs were produced. Check df_tda labels and Sophistication filters.\")\n",
    "\n",
    "df_soph_all = pd.concat(soph_results, ignore_index=True)\n",
    "\n",
    "# Drop any NC/invalid rows if they exist\n",
    "for col in [\"Impact\", \"Significance\", \"Trend\"]:\n",
    "    df_soph_all = df_soph_all[pd.to_numeric(df_soph_all[col], errors=\"coerce\").notna()]\n",
    "    df_soph_all[col] = df_soph_all[col].astype(float)\n",
    "\n",
    "# Classify sophistication\n",
    "df_soph_all[\"PredSoph\"] = df_soph_all.apply(classify_sophistication, axis=1)\n",
    "\n",
    "# ============================================================\n",
    "# Evaluate\n",
    "# ============================================================\n",
    "overall_acc = accuracy_score(df_soph_all[\"TrueSoph\"], df_soph_all[\"PredSoph\"])\n",
    "print(\"\\nOverall sophistication accuracy:\", overall_acc)\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    df_soph_all[\"TrueSoph\"],\n",
    "    df_soph_all[\"PredSoph\"],\n",
    "    labels=[\"Naive\", \"Knowledgeable\", \"Sophisticated\"]\n",
    ")\n",
    "print(\"\\nConfusion matrix rows=True, cols=Pred (Naive,Knowledgeable,Sophisticated):\\n\", cm)\n",
    "\n",
    "# Accuracy by tampering_percentage\n",
    "acc_by_pct = (\n",
    "    df_soph_all.assign(correct=(df_soph_all[\"TrueSoph\"] == df_soph_all[\"PredSoph\"]).astype(int))\n",
    "    .groupby([\"tampering_percentage\"])[\"correct\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"accuracy\")\n",
    ")\n",
    "print(\"\\nAccuracy by tampering percentage:\\n\", acc_by_pct)\n",
    "\n",
    "# ============================================================\n",
    "# Plots\n",
    "# ============================================================\n",
    "\n",
    "# 1) Scatter: Impact vs Trend (colored by PredSoph)\n",
    "plt.figure(figsize=(6, 4))\n",
    "for label in [\"Naive\", \"Knowledgeable\", \"Sophisticated\"]:\n",
    "    sub = df_soph_all[df_soph_all[\"PredSoph\"] == label]\n",
    "    plt.scatter(sub[\"Impact\"], sub[\"Trend\"], alpha=0.55, label=label)\n",
    "\n",
    "plt.xlabel(\"Impact\")\n",
    "plt.ylabel(\"Trend\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) Accuracy vs tampering percentage\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(acc_by_pct[\"tampering_percentage\"], acc_by_pct[\"accuracy\"], marker=\"o\")\n",
    "plt.xlabel(\"Tampering Percentage (%)\")\n",
    "plt.ylabel(\"Sophistication Classification Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Optional: show distributions of the three features\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(df_soph_all[\"Impact\"].values, bins=30, alpha=0.7)\n",
    "plt.xlabel(\"Impact\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ed289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_devide_to_microcell_dictionary(df):\n",
    "    temp_dictionary={}\n",
    "    unique_keys = df.gen_microcell.unique()\n",
    "    for microcell in unique_keys:\n",
    "        temp_dictionary[\"{}\".format(microcell)] = df[df.gen_microcell==microcell]\n",
    "    return temp_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9db0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Sophistication:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect_sophistication(self, correct_data, tampered_data, weight):\n",
    "        results_review = {}\n",
    "\n",
    "        df_sct = tampered_data\n",
    "        df_sct = df_sct[df_sct['label'] == 'T']\n",
    "        tampered_data = dataframe_devide_to_microcell_dictionary(df_sct)\n",
    "\n",
    "        for key2, df2 in tampered_data.items():\n",
    "            df2_received = df2[(df2['label'] == 'T') & (df2['origin'] == 'R')]\n",
    "            df2_generated = df2[(df2['label'] == 'T') & (df2['origin'] == 'G')]\n",
    "\n",
    "            if not df2_received.empty:\n",
    "                df2_received = self._process_received_data(df2_received, correct_data)\n",
    "\n",
    "            if not df2_generated.empty:\n",
    "                df2_generated = self._process_generated_data(df2_generated, correct_data, key2)\n",
    "\n",
    "            combined_microcell_df = pd.concat([df2_generated, df2_received])\n",
    "            combined_microcell_df = combined_microcell_df[combined_microcell_df['D_speed'] != 'NC']\n",
    "            combined_microcell_df = combined_microcell_df[(combined_microcell_df['speed'] != 0) &\n",
    "                                        (combined_microcell_df['latency'] != 0) &\n",
    "                                        (combined_microcell_df['bandwidth'] != 0) &\n",
    "                                        (combined_microcell_df['coverage'] != 0) &\n",
    "                                        (combined_microcell_df['reliability'] != 0) &\n",
    "                                        (combined_microcell_df['security'] != 0)]\n",
    "            combined_microcell_df=combined_microcell_df.reset_index(drop=True)\n",
    "            nc_count = combined_microcell_df['D_speed'].value_counts().get('NC', 0)\n",
    "            total_count = len(combined_microcell_df['D_speed'])\n",
    "\n",
    "            # print(\"Microcell:\", key2)\n",
    "            # print(\"Count of 'NC':\", nc_count)\n",
    "            # print(\"Total count:\", total_count)\n",
    "\n",
    "            results_review[key2] = combined_microcell_df\n",
    "        # print(\"*********second part************\")\n",
    "        out_data={}\n",
    "        for key, df in results_review.items():\n",
    "            df=df.reset_index(drop=True)\n",
    "            \n",
    "            sample_list =[]\n",
    "\n",
    "            impact = self._calculate_impact(df, weight)\n",
    "            sig = self._calculate_significance(df, weight)\n",
    "            trend = self._calculate_trend(df,correct_data)\n",
    "            data = {'Impact': impact, 'Significance': sig, 'Trend': trend}\n",
    "\n",
    "            new_df = pd.DataFrame(data)\n",
    "            new_df = new_df[new_df['Trend'] != 'NC']\n",
    "            new_df=new_df.reset_index(drop=True)\n",
    "            # print(key,new_df.shape[0])\n",
    "            out_data[key] = new_df\n",
    "            # print(new_df)\n",
    "            # results_review[key2]= new_df\n",
    "\n",
    "        return out_data\n",
    "\n",
    "    def _process_received_data(self, df_received, correct_data):\n",
    "        for i, row in df_received.iterrows():\n",
    "            origin_record = correct_data[correct_data['serviceid'] == row['serviceid']]\n",
    "            for attr in ['speed', 'latency', 'bandwidth', 'coverage', 'reliability', 'security']:\n",
    "                df_received.at[i, f'D_{attr}'] = origin_record[attr].values[0] if not origin_record.empty else 'NC'\n",
    "        return df_received\n",
    "\n",
    "    def _process_generated_data(self, df_generated, correct_data, key2):\n",
    "        for i, row in df_generated.iterrows():\n",
    "            provider_other_df = correct_data[(correct_data['providerid'] == row['providerid']) & (correct_data['microcell'] != key2)]\n",
    "            if len(provider_other_df) > 1:\n",
    "                mean_values = provider_other_df[['speed', 'latency', 'bandwidth', 'coverage', 'reliability', 'security']].mean()\n",
    "                df_generated.loc[i, 'D_speed':'D_security'] = mean_values.values\n",
    "            else:\n",
    "                df_generated.loc[i, 'D_speed':'D_security'] = 'NC'\n",
    "        return df_generated\n",
    "    def _calculate_impact(self, df_row, weight):\n",
    "        d_speed = df_row['speed'] - df_row['D_speed']\n",
    "        d_latency = df_row['latency'] - df_row['D_latency']\n",
    "        d_bandwidth = df_row['bandwidth'] - df_row['D_bandwidth']\n",
    "        d_coverage = df_row['coverage'] - df_row['D_coverage']\n",
    "        d_reliability = df_row['reliability'] - df_row['D_reliability']\n",
    "        d_security = df_row['security'] - df_row['D_security']\n",
    "\n",
    "        impact = (d_speed * weight[0] + d_latency * weight[1] + d_bandwidth * weight[2] +\n",
    "                d_coverage * weight[3] + d_reliability * weight[4] + d_security * weight[5]).div(5)\n",
    "        impact = impact.clip(lower=0)\n",
    "        return impact\n",
    "\n",
    "    def _calculate_significance(self, df_row, weight1):\n",
    "        power = 1  # You can adjust this power value to enhance the weights of higher values\n",
    "        powered_matrix = [x ** power for x in weight1]\n",
    "        total_sum = sum(powered_matrix)\n",
    "        weight = [x / total_sum for x in powered_matrix]\n",
    "        # print(weight)\n",
    "        sig_list = []\n",
    "        for i in range(len(df_row)):\n",
    "            if (df_row.iloc[i]['speed'] == df_row.iloc[i]['latency'] == df_row.iloc[i]['bandwidth'] ==\n",
    "                    df_row.iloc[i]['coverage'] == df_row.iloc[i]['reliability'] == df_row.iloc[i]['security']):\n",
    "                sig_list.append(0)\n",
    "            else:\n",
    "                percent_speed = (df_row.iloc[i]['speed'] - df_row.iloc[i]['D_speed'])\n",
    "                percent_latency = (df_row.iloc[i]['latency'] - df_row.iloc[i]['D_latency'])\n",
    "                percent_bandwidth = (df_row.iloc[i]['bandwidth'] - df_row.iloc[i]['D_bandwidth'])\n",
    "                percent_coverage = (df_row.iloc[i]['coverage'] - df_row.iloc[i]['D_coverage'])\n",
    "                percent_reliability = (df_row.iloc[i]['reliability'] - df_row.iloc[i]['D_reliability'])\n",
    "                percent_security = (df_row.iloc[i]['security'] - df_row.iloc[i]['D_security'])\n",
    "                num_changed = sum(abs(percent_change) > 0 for percent_change in\n",
    "                  [percent_speed, percent_latency, percent_bandwidth, percent_coverage,\n",
    "                   percent_reliability, percent_security])\n",
    "                \n",
    "                significance =  (1 if percent_speed > 0 else 0)  * weight[0] + \\\n",
    "                            (1 if percent_latency > 0 else 0)   * weight[1] + \\\n",
    "                            (1 if percent_bandwidth > 0 else 0)  * weight[2] + \\\n",
    "                            (1 if percent_coverage > 0 else 0)  * weight[3] + \\\n",
    "                            (1 if percent_reliability > 0 else 0)  * weight[4] + \\\n",
    "                            (1 if percent_security > 0 else 0) * weight[5]\n",
    "                \n",
    "                # significance =  percent_speed  * weight[0] + \\\n",
    "                #             percent_latency  * weight[1] + \\\n",
    "                #             percent_bandwidth * weight[2] + \\\n",
    "                #             percent_coverage * weight[3] + \\\n",
    "                #             percent_reliability * weight[4] + \\\n",
    "                #             percent_security* weight[5]\n",
    "\n",
    "                \n",
    "                significance = max(significance,0)\n",
    "                sig_list.append((significance) / num_changed)\n",
    "           \n",
    "                \n",
    "        return sig_list\n",
    "\n",
    "    def _calculate_trend(self, df_row, dfcorrect):\n",
    "        trend_list = []\n",
    "        for i in range(len(df_row)):\n",
    "            if (df_row.iloc[i]['speed'] == df_row.iloc[i]['latency'] == df_row.iloc[i]['bandwidth'] ==\n",
    "                    df_row.iloc[i]['coverage'] == df_row.iloc[i]['reliability'] == df_row.iloc[i]['security']):\n",
    "                trend_list.append(0)\n",
    "            else:\n",
    "                temp_df = dfcorrect[dfcorrect['providerid'] == df_row.iloc[i]['providerid']]\n",
    "                temp_df = temp_df[temp_df['serviceid'] != df_row.iloc[i]['serviceid']]\n",
    "                if temp_df.shape[0] > 0:\n",
    "                    s_mean = temp_df['speed'].mean()\n",
    "                    l_mean = temp_df['latency'].mean()\n",
    "                    b_mean = temp_df['bandwidth'].mean()\n",
    "                    c_mean = temp_df['coverage'].mean()\n",
    "                    r_mean = temp_df['reliability'].mean()\n",
    "                    sec_mean = temp_df['security'].mean()\n",
    "\n",
    "                    s_trend = df_row.iloc[i]['speed'] - s_mean\n",
    "                    l_trend = df_row.iloc[i]['latency'] - l_mean\n",
    "                    b_trend = df_row.iloc[i]['bandwidth'] - b_mean\n",
    "                    c_trend = df_row.iloc[i]['coverage'] - c_mean\n",
    "                    r_trend = df_row.iloc[i]['reliability'] - r_mean\n",
    "                    sec_trend = df_row.iloc[i]['security'] - sec_mean\n",
    "                    normalized_s_trend = self._normalize_trend(s_trend)\n",
    "                    normalized_l_trend = self._normalize_trend(l_trend)\n",
    "                    normalized_b_trend = self._normalize_trend(b_trend)\n",
    "                    normalized_c_trend = self._normalize_trend(c_trend)\n",
    "                    normalized_r_trend = self._normalize_trend(r_trend)\n",
    "                    normalized_sec_trend = self._normalize_trend(sec_trend)\n",
    "\n",
    "                    total_trend = (normalized_s_trend + normalized_l_trend + normalized_b_trend +\n",
    "                                normalized_c_trend + normalized_r_trend + normalized_sec_trend) / 6\n",
    "                    total_trend = max(total_trend,0)\n",
    "                else:\n",
    "                    total_trend = 'NC'\n",
    "                trend_list.append(total_trend)\n",
    "           \n",
    "                \n",
    "        return trend_list\n",
    "\n",
    "    def _normalize_trend(self, trend_value):\n",
    "        min_value = 0\n",
    "        max_value = 5\n",
    "        score = 1 - (trend_value - min_value) / (max_value - min_value)\n",
    "        return max(0, min(score, 1))\n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "sophistication = Sophistication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5df559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evaluations.evaluation_data.evaluation_data import EvaluationData\n",
    "from tampering.tampering import Tampering\n",
    "from timf.timf import TIMF\n",
    "from data_service.data_service import DataService\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "evaluation_data = EvaluationData()\n",
    "tampering = Tampering()\n",
    "        \n",
    "data_service = DataService()\n",
    "timf = TIMF(data_service)\n",
    "\n",
    "data = evaluation_data.get_data()\n",
    "sophistication =Sophistication()\n",
    "\n",
    "\n",
    "tampering_percentages = list(range(10, 100, 20))\n",
    "\n",
    "tampering_types = [\"N\", \"K\", \"S\"]  # Naive, Knowledgeable, Sophisticated\n",
    "# tampering_types = [\"N\"]\n",
    "        \n",
    "results = []\n",
    "\n",
    "def _haversine_km(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371.0 * c\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def compute_metrics_from_labels(y_true_labels, y_pred_labels):\n",
    "    \"\"\"\n",
    "    Inputs are arrays/Series with values 'T' or 'C'\n",
    "    \"\"\"\n",
    "    y_true = (pd.Series(y_true_labels) == 'T').astype(int)\n",
    "    y_pred = (pd.Series(y_pred_labels) == 'T').astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        auc = None\n",
    "\n",
    "    return accuracy, precision, recall, auc\n",
    "\n",
    "\n",
    "results_metrics = []\n",
    "\n",
    "for tampering_type in tampering_types:\n",
    "    for tampering_percentage in tampering_percentages:\n",
    "\n",
    "        print(f\"Experiment: Tampering Type={tampering_type}, Percentage={tampering_percentage}%\")\n",
    "\n",
    "        for assessing_mic in data['gen_microcell'].unique():\n",
    "\n",
    "            df_microcell = data[data['gen_microcell'] == assessing_mic]\n",
    "\n",
    "            # -------- Remote tampering (BMA) --------\n",
    "            bma_tampered_df = tampering.bma_tampering(data[data['gen_microcell'] != assessing_mic].reset_index(drop=True),tampering_percentage, tampering_type)\n",
    "            remote_data = bma_tampered_df.copy()\n",
    "\n",
    "            # -------- Replication logic --------\n",
    "            microcell_coords = data.groupby('gen_microcell')[['latitude', 'longitude']].first().reset_index()\n",
    "            current_coords = microcell_coords[microcell_coords['gen_microcell'] == assessing_mic]\n",
    "\n",
    "            if not current_coords.empty:\n",
    "                lat1 = current_coords['latitude'].values[0]\n",
    "                lon1 = current_coords['longitude'].values[0]\n",
    "\n",
    "                df_microcell_part = df_microcell.copy()\n",
    "                df_microcell_part.loc[:, 'currect_microcell'] = assessing_mic\n",
    "\n",
    "                replicated_parts = [df_microcell_part]\n",
    "\n",
    "                for provider_id in df_microcell['providerid'].unique():\n",
    "\n",
    "                    provider_remote = remote_data[remote_data['providerid'] == provider_id]\n",
    "                    candidate_microcells = []\n",
    "\n",
    "                    for _, row in microcell_coords.iterrows():\n",
    "                        if row['gen_microcell'] == assessing_mic:\n",
    "                            continue\n",
    "                        if (provider_remote['gen_microcell'] == row['gen_microcell']).any():\n",
    "                            dist = _haversine_km(lat1, lon1, row['latitude'], row['longitude'])\n",
    "                            candidate_microcells.append((row['gen_microcell'], dist))\n",
    "\n",
    "                    candidate_microcells.sort(key=lambda x: x[1])\n",
    "                    nearby_microcells = [m for m, _ in candidate_microcells[:10]]\n",
    "\n",
    "                    if nearby_microcells:\n",
    "                        df_remote = remote_data[\n",
    "                            (remote_data['providerid'] == provider_id) &\n",
    "                            (remote_data['gen_microcell'].isin(nearby_microcells))\n",
    "                        ].drop_duplicates(subset='serviceid')\n",
    "\n",
    "                        if not df_remote.empty:\n",
    "                            df_remote['origin'] = 'R'\n",
    "                            df_remote['currect_microcell'] = assessing_mic\n",
    "                            replicated_parts.append(df_remote)\n",
    "\n",
    "                df_microcell_replicated = pd.concat(replicated_parts, ignore_index=True)\n",
    "            else:\n",
    "                df_microcell_replicated = df_microcell.copy()\n",
    "\n",
    "            # -------- Local tampering (SPA) --------\n",
    "            spa_tampered_df = tampering.spa_tampering(\n",
    "                df_microcell_replicated,\n",
    "                type=tampering_type\n",
    "            )\n",
    "\n",
    "            # -------- Set TIMF data --------\n",
    "            data_service.set_local_data(spa_tampered_df.copy())\n",
    "\n",
    "            # --- Full remote pool (all other microcells) ---\n",
    "            remote_data_set = data[data['gen_microcell'] != assessing_mic].copy()\n",
    "\n",
    "            # --- Select 50% of microcells (availability by microcell) ---\n",
    "            rng = np.random.default_rng(42)   # fixed seed for reproducibility\n",
    "            uni_mic = remote_data_set['gen_microcell'].unique()\n",
    "\n",
    "            selected_mics = rng.choice(\n",
    "                uni_mic,\n",
    "                size=max(1, int(len(uni_mic) * 0.8)),   # \n",
    "                replace=False\n",
    "            )\n",
    "\n",
    "            # --- Keep only records from selected microcells ---\n",
    "            remote_available = remote_data_set[remote_data_set['gen_microcell'].isin(selected_mics)].copy()\n",
    "\n",
    "            # --- Set remote data (partial availability) ---\n",
    "            data_service.set_remote_data(remote_available)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for provider in df_microcell['providerid'].unique():\n",
    "\n",
    "                # ---------- TDA ----------\n",
    "                _, df_tda, time_df = timf.trust_assessment(provider, assessing_mic)\n",
    "                print(sophistication.detect_sophistication(df_microcell_replicated,df_tda,[0.3,0.1,0.2,0.1,0.1,0.2]))\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16dc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbb59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44333114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
